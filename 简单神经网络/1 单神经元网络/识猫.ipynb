{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这是一个用于识别猫的程序。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # 加载numpy工具库并给它取个别名为np\r\n",
    "import matplotlib.pyplot as plt # 用来画图的\r\n",
    "\r\n",
    "import h5py # 用来加载训练数据集的。我们数据集的保存格式是HDF。Hierarchical Data Format(HDF)是一种针对大量数据进行组织和存储的文件格式\r\n",
    "import skimage.transform as tf # 用来缩放图片\r\n",
    "\r\n",
    "#这是jupyter notebook里的命令, 意思是将那些用matplotlib绘制的图显示在页面里而不是弹出一个窗口\r\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "人工智能是需要用很多数据来进行训练的。我已经为大家准备好了数据，文档同目录下的datasets文件夹就是存放数据集的地方。下面这个函数用于加载这些数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    train_dataset = h5py.File('datasets/train_catvnoncat.h5', \"r\") # 加载训练数据\n",
    "    train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:]) # 从训练数据中提取出图片的特征数据\n",
    "    train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:]) # 从训练数据中提取出图片的标签数据\n",
    "\n",
    "    test_dataset = h5py.File('datasets/test_catvnoncat.h5', \"r\") # 加载测试数据\n",
    "    test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:]) \n",
    "    test_set_y_orig = np.array(test_dataset[\"test_set_y\"][:]) \n",
    "\n",
    "    classes = np.array(test_dataset[\"list_classes\"][:]) # 加载标签类别数据，这里的类别只有两种，1代表有猫，0代表无猫\n",
    "        \n",
    "    train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[0])) # 把数组的维度从(209,1)变成(1, 209)，这样好方便后面进行计算\n",
    "    test_set_y_orig = test_set_y_orig.reshape((1, test_set_y_orig.shape[0])) # 从(50,1)变成(1, 50)\n",
    "    \n",
    "    return train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 调用上面定义的函数将数据加载到各个变量中\n",
    "train_set_x_orig, train_set_y, test_set_x_orig, test_set_y, classes = load_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面我们随便挑一张图片将其显示出来，给大家一个直观的认识。下面的index你们可以随便改动。图片的像素很低，是因为如果用高像素图片的话就会需要更多的计算时间。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 30\n",
    "plt.imshow(train_set_x_orig[index])\n",
    "print (\"标签为\" + str(train_set_y[:, index]) + \", 这是一个'\" + classes[np.squeeze(train_set_y[:, index])].decode(\"utf-8\") +  \"' 图片.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 我们要清楚变量的维度，否则后面会出很多问题。下面我把他们的维度打印出来。\n",
    "print (\"train_set_x_orig shape: \" + str(train_set_x_orig.shape))\n",
    "print (\"train_set_y shape: \" + str(train_set_y.shape))\n",
    "print (\"test_set_x_orig shape: \" + str(test_set_x_orig.shape))\n",
    "print (\"test_set_y shape: \" + str(test_set_y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面train_set_x_orig的各维度的含义分别是(样本数，图片宽，图片长，3个RGB通道)\n",
    "\n",
    "我们后面要用到样本数和长宽像素值，下面我分别把它们提取出来了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_train = train_set_x_orig.shape[0]\n",
    "m_test = test_set_x_orig.shape[0]\n",
    "num_px = test_set_x_orig.shape[1] # 由于我们的图片是正方形的，所以长宽相等\n",
    "\n",
    "print (\"训练样本数: m_train = \" + str(m_train))\n",
    "print (\"测试样本数: m_test = \" + str(m_test))\n",
    "print (\"每张图片的宽/高: num_px = \" + str(num_px))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 为了方便后面进行矩阵运算，我们需要将样本数据进行扁平化和转置\r\n",
    "# 处理后的数组各维度的含义是（图片数据，样本数）\r\n",
    "train_set_x_flatten = train_set_x_orig.reshape(train_set_x_orig.shape[0], -1).T\r\n",
    "test_set_x_flatten = test_set_x_orig.reshape(test_set_x_orig.shape[0], -1).T \r\n",
    "\r\n",
    "print (\"train_set_x_flatten shape: \" + str(train_set_x_flatten.shape))\r\n",
    "print (\"test_set_x_flatten shape: \" + str(test_set_x_flatten.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下面我们对特征数据进行了简单的标准化处理（除以255，使所有值都在[0，1]范围内）\n",
    "# 为什么要对数据进行标准化处理呢？简单来说就是为了方便后面进行计算。\n",
    "\n",
    "train_set_x = train_set_x_flatten/255.\n",
    "test_set_x = test_set_x_flatten/255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面我们已经加载了数据，并且对数据进行了预处理，使其便于进行后面的运算。后面我们将会构建一个如下图所示的神经网络模型来对上面的数据进行运算。\r\n",
    "\r\n",
    "![1.png](./images/1.png)\r\n",
    "\r\n",
    "为了构建上面的神经网络，我们需要先编写一些工具函数，这些函数会对上面的数据进行特定功能的运算。最后再将这些单独的函数组合起来，构建出一个神经网络模型。\r\n",
    "\r\n",
    "第一个编写的工具函数是sigmoid。前面文章我已经介绍过它了，sigmoid函数的作用就是把预测结果转换为0和1之间的值，不明白的复习下前面的文章。下面是sigmoid的数学公式和图示。\r\n",
    "\r\n",
    "![2.png](./images/2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \"\"\"\n",
    "    参数:\n",
    "    z -- 一个数值或者一个numpy数组.\n",
    "    返回值:\n",
    "    s -- 经过sigmoid算法计算后的值，在[0,1]范围内\n",
    "    \"\"\"\n",
    "    s = 1 / (1 + np.exp(-z))    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_with_zeros(dim):\n",
    "    \"\"\"\n",
    "    这个函数用于初始化权重数组w和偏置/阈值b.\n",
    "    \n",
    "    参数:\n",
    "    dim -- w的大小，看上面的神经网络模型图可知，dim在本例中是12288，因为一个特征输入对应一个权重。\n",
    "    \n",
    "    返回值:\n",
    "    w -- 权重数组\n",
    "    b -- 偏置bias\n",
    "    \"\"\"\n",
    "\n",
    "    w = np.zeros((dim,1))\n",
    "    b = 0\n",
    "    \n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面的函数用于执行前向传播，计算出成本cost；以及执行反向传播，计算出w和b的偏导数/梯度，后面会被用来进行梯度下降。\r\n",
    "\r\n",
    "前向传播会用到下面两个公式\r\n",
    "\r\n",
    "![3.png](./images/3.png)\r\n",
    "\r\n",
    "![4.png](./images/4.png)\r\n",
    "\r\n",
    "反向传播会用到下面两个公式，计算dw和db。\r\n",
    "\r\n",
    "![5.png](./images/5.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def propagate(w, b, X, Y):\n",
    "    \"\"\"\n",
    "    参数:\n",
    "    w -- 权重数组，维度是(12288, 1)\n",
    "    b -- 偏置bias\n",
    "    X -- 图片的特征数据，维度是 (12288, 209)\n",
    "    Y -- 图片对应的标签，0或1，0是无猫，1是有猫，维度是(1,209)\n",
    "\n",
    "    返回值:\n",
    "    cost -- 成本\n",
    "    dw -- w的梯度\n",
    "    db -- b的梯度\n",
    "    \"\"\"\n",
    "    \n",
    "    m = X.shape[1]\n",
    "    \n",
    "    # 前向传播\n",
    "    A = sigmoid(np.dot(w.T, X) + b)                             \n",
    "    cost = -np.sum(Y*np.log(A) + (1-Y)*np.log(1-A)) / m  \n",
    "    \n",
    "    # 反向传播\n",
    "    dZ = A - Y\n",
    "    dw = np.dot(X,dZ.T) / m\n",
    "    db = np.sum(dZ) / m\n",
    "    \n",
    "    # 将dw和db保存到字典里面\n",
    "    grads = {\"dw\": dw,\n",
    "             \"db\": db}\n",
    "    \n",
    "    return grads, cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面的函数通过梯度下降算法来更新参数w和b，达到越来越优化的目的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(w, b, X, Y, num_iterations, learning_rate, print_cost = False):\n",
    "    \"\"\"    \n",
    "    参数:\n",
    "    w -- 权重数组，维度是 (12288, 1)\n",
    "    b -- 偏置bias\n",
    "    X -- 图片的特征数据，维度是 (12288, 209)\n",
    "    Y -- 图片对应的标签，0或1，0是无猫，1是有猫，维度是(1,209)\n",
    "    num_iterations -- 指定要优化多少次\n",
    "    learning_rate -- 学习步进，是我们用来控制优化步进的参数\n",
    "    print_cost -- 为True时，每优化100次就把成本cost打印出来,以便我们观察成本的变化\n",
    "    \n",
    "    返回值:\n",
    "    params -- 优化后的w和b\n",
    "    costs -- 每优化100次，将成本记录下来，成本越小，表示参数越优化\n",
    "    \"\"\"\n",
    "    \n",
    "    costs = []\n",
    "    \n",
    "    for i in range(num_iterations):        \n",
    "        grads, cost = propagate(w, b, X, Y) # 计算得出梯度和成本\n",
    "                \n",
    "        # 从字典中取出梯度\n",
    "        dw = grads[\"dw\"]\n",
    "        db = grads[\"db\"]\n",
    "        \n",
    "        # 进行梯度下降，更新参数，使其越来越优化，使成本越来越小\n",
    "        w = w - learning_rate * dw\n",
    "        b = b - learning_rate * db\n",
    "        \n",
    "        # 将成本记录下来\n",
    "        if i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "            if print_cost:\n",
    "                print (\"优化%i次后成本是: %f\" %(i, cost))\n",
    "    \n",
    "    params = {\"w\": w,\n",
    "              \"b\": b}\n",
    "    return params, costs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面的函数会得出优化后的参数w和b。训练神经网络，其实就是通过使用海量数据来进行训练，从而得出这些优化后的参数。有了这些参数后，我们就可以使用它们来进行预测了，对于本文章来说，也就是可以用这些参数来对新的任意图片进行预测了——预测图片里有猫或没有猫——最后面会告诉大家如何来预测你自己提供的任意图片。\n",
    "\n",
    "下面这个函数会使用输入的参数w和b来对输入的待预测数据X进行预测。X可以是一张图片也可以是多张图片，当多张图片时，函数会给出对每张图片的预测结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(w, b, X):\n",
    "    '''    \n",
    "    参数:\n",
    "    w -- 权重数组，维度是 (12288, 1)\n",
    "    b -- 偏置bias\n",
    "    X -- 图片的特征数据，维度是 (12288, 图片张数)\n",
    "    \n",
    "    返回值:\n",
    "    Y_prediction -- 对每张图片的预测结果\n",
    "    '''    \n",
    "    m = X.shape[1]\n",
    "    Y_prediction = np.zeros((1,m))\n",
    "       \n",
    "    A = sigmoid(np.dot(w.T, X) + b)  # 通过这行代码来对图片进行预测\n",
    "    \n",
    "    # 上面得出的预测结果是小数的形式，为了方便后面显示，我们将其转换成0和1的形式（大于等于0.5就是1/有猫，小于0.5就是0/无猫）\n",
    "    for i in range(A.shape[1]):\n",
    "        if A[0,i] >= 0.5:\n",
    "            Y_prediction[0,i] = 1\n",
    "    \n",
    "    return Y_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "到此，我们已经编写了所需的所有工具函数了。下面我们将这些函数组合起来，构建出一个最终的神经网络模型函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, X_test, Y_test, num_iterations = 2000, learning_rate = 0.5, print_cost = False):\n",
    "    \"\"\"    \n",
    "    参数:\n",
    "    X_train -- 训练图片,维度是(12288, 209)\n",
    "    Y_train -- 训练图片对应的标签,维度是 (1, 209)\n",
    "    X_test -- 测试图片,维度是(12288, 50)\n",
    "    Y_test -- 测试图片对应的标签,维度是 (1, 50)\n",
    "    num_iterations -- 需要训练/优化多少次\n",
    "    learning_rate -- 学习步进，是我们用来控制优化步进的参数\n",
    "    print_cost -- 为True时，每优化100次就把成本cost打印出来,以便我们观察成本的变化\n",
    "    \n",
    "    返回值:\n",
    "    d -- 返回一些信息\n",
    "    \"\"\"\n",
    "    \n",
    "    # 初始化待训练的参数\n",
    "    w, b = initialize_with_zeros(X_train.shape[0])\n",
    "\n",
    "    # 使用训练数据来训练/优化参数\n",
    "    parameters, costs = optimize(w, b, X_train, Y_train, num_iterations, learning_rate, print_cost)\n",
    "    \n",
    "    # 从字典中分别取出训练好的w和b\n",
    "    w = parameters[\"w\"]\n",
    "    b = parameters[\"b\"]\n",
    "    \n",
    "    # 使用训练好的w和b来分别对训练图片和测试图片进行预测\n",
    "    Y_prediction_train = predict(w, b, X_train)\n",
    "    Y_prediction_test = predict(w, b, X_test)\n",
    "    \n",
    "    # 打印出预测的准确率\n",
    "    print(\"对训练图片的预测准确率为: {}%\".format(100 - np.mean(np.abs(Y_prediction_train - Y_train)) * 100))\n",
    "    print(\"对测试图片的预测准确率为: {}%\".format(100 - np.mean(np.abs(Y_prediction_test - Y_test)) * 100))\n",
    "\n",
    "    \n",
    "    d = {\"costs\": costs,\n",
    "         \"Y_prediction_test\": Y_prediction_test, \n",
    "         \"Y_prediction_train\" : Y_prediction_train, \n",
    "         \"w\" : w, \n",
    "         \"b\" : b,\n",
    "         \"learning_rate\" : learning_rate,\n",
    "         \"num_iterations\": num_iterations}\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 调用上面的模型函数对我们最开始加载的数据进行训练\n",
    "d = model(train_set_x, train_set_y, test_set_x, test_set_y, num_iterations = 2000, learning_rate = 0.005, print_cost = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从上面打印出的信息可知，随着优化的次数越来越多，成本越来越小，说明优化后的参数使预测越来越准确了。\n",
    "对于训练图片的预测准确率达到了99%。\n",
    "对于测试图片是70%，其实已经很不错了，因为出于教学的目的，我们的训练数据集很小，而且构建的是最最简单的单神经元神经网络，后面我会教大家构建更加强大更加复杂的神经网络的！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这里我们可以改变index，来看看哪些图片预测对了\n",
    "index = 5\n",
    "plt.imshow(test_set_x[:,index].reshape((num_px, num_px, 3)))\n",
    "print (\"这张图的标签是 \" + str(test_set_y[0,index]) + \", 预测结果是 \" + str(int(d[\"Y_prediction_test\"][0,index])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下面我们打印出成本随着训练次数增加时的变化情况。可以很直观的看出，训练次数越多，成本越小，也就是预测结果更精确\n",
    "costs = np.squeeze(d['costs'])\n",
    "plt.plot(costs)\n",
    "plt.ylabel('cost') # 成本\n",
    "plt.xlabel('iterations (per hundreds)') # 横坐标为训练次数，以100为单位\n",
    "plt.title(\"Learning rate =\" + str(d[\"learning_rate\"]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "选择一个正确的学习步进/学习率很重要。选错了，那么你的神经网络可能会永远找不到损失函数的最小值处，即你的神经网络预测得永远不会很准。下面我使用了3个不同的学习率来给大家直观地展示展示它们对训练过程的影响。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates = [0.01, 0.001, 0.0001]\n",
    "models = {}\n",
    "for i in learning_rates:\n",
    "    print (\"学习率为: \" + str(i) + \"时\")\n",
    "    models[str(i)] = model(train_set_x, train_set_y, test_set_x, test_set_y, num_iterations = 1500, learning_rate = i, print_cost = False)\n",
    "    print ('\\n' + \"-------------------------------------------------------\" + '\\n')\n",
    "\n",
    "for i in learning_rates:\n",
    "    plt.plot(np.squeeze(models[str(i)][\"costs\"]), label= str(models[str(i)][\"learning_rate\"]))\n",
    "\n",
    "plt.ylabel('cost')\n",
    "plt.xlabel('iterations (hundreds)')\n",
    "\n",
    "legend = plt.legend(loc='upper center', shadow=True)\n",
    "frame = legend.get_frame()\n",
    "frame.set_facecolor('0.90')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到，上面其它的代码都是一样的，只有学习率不同，就会导致预测的准确率不同。在以后的文章中，我会教大家如何选择合适的学习率。\n",
    "\n",
    "到此，你已经学会了构建一个最简单的神经网络了。看懂了本篇文章，那就说明你已经入门人工智能领域了。恭喜恭喜！\n",
    "\n",
    "下面的代码向大家展示了如何使用上面构建的神经网络来预测我们自己的图片。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在本文档的同目录下创建一个文件夹images,把你的任意图片改名成my_image1.jpg后放入文件夹\r\n",
    "my_image = \"test2.jpg\" # test1.jpg、test2.jpg、test3.jpg\r\n",
    "fname = \"images/\" + my_image\r\n",
    "\r\n",
    "image = np.array(plt.imread(fname))\r\n",
    "my_image = tf.resize(image,(num_px,num_px), mode='reflect').reshape((1, num_px*num_px*3)).T\r\n",
    "my_predicted_image = predict(d[\"w\"], d[\"b\"], my_image)\r\n",
    "\r\n",
    "plt.imshow(image)\r\n",
    "print(\"预测结果为 \" + str(int(np.squeeze(my_predicted_image))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python385jvsc74a57bd007efdcd4b820c98a756949507a4d29d7862823915ec7477944641bea022f4f62"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}