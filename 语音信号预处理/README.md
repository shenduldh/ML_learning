# 语音信号处理

## 语音信息处理步骤

<img src="../assets/image-20211209001553423.png" alt="image-20211209001553423" style="zoom:50%;" />

1. 语音信号数字化之前，必须先进行==防混叠滤波及防工频干扰滤波==。防混叠滤波指滤除高于1/2采样频率的信号成分或噪声，使信号带宽限制在某个范围内；否则，若采样率不满足采样定理，则会产生频谱混叠，此时信号中的高频成分将产生失真。工频干扰指50Hz的电源干扰。

2. 语音信号是时间和幅度都连续变化的一维模拟信号，要想在计算机中对它进行处理，就要先进行==采样和量化==，将它变成==时间和幅度都离散==的数字信号。将语音模拟信号表示成可以处理的函数形式$x_a(t)$，它表示函数值随着连续时间变量t的变化趋势。如果以一定的时间间隔T对这样的连续信号取值，则连续信号$x_a(t)$变成离散信号$x(n)＝x_a(nT)$，这个过程称为采样，其中两个取样点之间的间隔T称为采样周期，它的倒数$F_s$称为采样频率。根据采样定理，当采样频率大于信号最高频率的两倍时，在采样过程中就不会丢失信息，并且可以用采样后的信号重构原始信号。在实际的语音信号处理中，采样频率一般为8~10kHz。为了实现更高质量的语音识别，可将处理的语音信号扩展到7~9kHz，这时的采样频率一般为15~20kHz。将8kHz采样率时的系统作为基线系统，当采样率为11kHz时，系统的误识率有10%的降低；继续升高采样率到16kHz时，系统的误识率与11kHz相比有10%的降低；当采样率继续增加时，误识率几乎没有降低。因此在一般的识别系统中，采样率最高选择在16kHz。

   <img src="https://res.weread.qq.com/wrepub/epub_27111671_66" alt="epub_27111671_66" style="zoom: 20%;" />

3. 上图的下半部分为一段模拟信号，其上半部分为对应的离散信号。可见，采样后的信号在时间域上是离散的形式，但在幅度上还保持着连续的特点，所以要进行量化。==量化的目的是将信号波形的幅度值离散化。==一个量化器就是将整个信号的幅度值分成若干个有限的区间，并且把落入同一个区间的样本点都用同一个幅度值表示，这个幅度值称为量化值。量化方式有3种：零记忆量化、分组量化和序列量化。零记忆量化是每次量化一个模拟采样值，并对所有采样点都使用相同的量化器特性。分组量化是从可能输出组的离散集合中，选出一组输出值，代表一组输入的模拟采样值。序列量化是在分组或非分组的基础上，用一些邻近采样点的信息对采样序列进行量化。

   - 零记忆量化的输入-输出特性采用阶梯形函数的形式。下图给出了两种量化器特性。中点上升量化器的输出没有零电平，在零附近有两个输入区间；正区间产生正输出电平，负区间产生负输出电平。中点水平量化器有零电平输出，它对应于零输入区间。量化范围和电平可以用不同方法选取，但通常都是均匀分布的。

     <img src="https://res.weread.qq.com/wrepub/epub_27111671_67" alt="epub_27111671_67" style="zoom: 12%;" />

     一般量化值都用二进制来表示，如果用B个二进制数表示量化值，即量化字长，那么一般将幅度值划分为2B个等分区间。从量化的过程可以看出，信号在经过量化后，一定存在一个量化误差：$e(n)=\hat{x}(n)-x(n)$。其中，e(n)为量化误差或噪声；$\hat{x}(n)$为量化后的采样值，即量化器的输出；x(n)为未量化的采样值，即量化器的输入。对于上图中的两种量化器，当按$2x_{max}＝Δ×2B$选定Δ和B时，量化误差的变化范围为$-\frac{\Delta}{2} \leqslant e(n) \leqslant \frac{\Delta}{2}$。其中，$x_{max}$表示信号的峰值。当信号波形的变化足够大或量化间隔Δ足够大时，可以证明量化噪声符合具有下列特性的统计模型：①它是一个平稳的白噪声过程；②量化噪声和输入信号相互独立；③量化噪声在量化间隔内均匀分布，即具有等概率密度分布。

     若用 $\sigma_{x}^{2}$ 表示输入语音信号序列的方差，$ \sigma_{e}^{2}$ 表示噪声序列的方差，则可以证明量化信噪比SNR (dB) 为$\mathrm{SNR}=10 \lg \left(\frac{\sigma_{x}^{2}}{\sigma_{e}^{2}}\right)=6.02 B+4.77-20 \log \left(\frac{x_{\max }}{\sigma_{x}}\right)$。假设语音信号的幅度服从拉普拉斯分布，此时信号幅度超过$4 \sigma_{x}$ 的概率很小，只有0.35%，因而可以取$x_{\max }=4 \sigma_{x} $。此时上式变为$\mathrm{SNR}=6.02 B-7.2$。该式表明：量化器中每个比特字长对信噪比的贡献大约为6dB。当量化字长为7比特时，信噪比为35dB。此时量化后的语音质量能满足一般通信系统的要求。然而研究表明，语音波形的动态范围达55dB，故量化字长应取10比特以上。

4. 经过采样和量化过程后，一般还要对语音信号进行一些==预加重==。其目的就是提升高频部分，使信号的频谱变得平坦，便于进行频谱分析或声道参数分析。预加重可以在A/D变换前，在防混叠滤波之前进行，这样不仅能够进行预加重，而且可以压缩信号的动态范围，有效地提高信噪比。预加重也可以在A/D变换之后进行，用具有6dB/倍频程提升高频特性的预加重数字滤波器实现，预加重滤波器一般是一阶的，形式为：$H(z)=1-u z^{-1}$。其中，u值接近1，典型的取值为0.94~0.97。预加重后的信号在分析处理之后，需要进行去加重处理，即加上-6dB/倍频程下降的频率特性来还原成原来的特性。

   <img src="../assets/image-20211129135752120.png" alt="image-20211129135752120" style="zoom: 50%;" />

5. 分帧和加窗：分帧用于将整体信号分成一段一段平稳的局部信号，加窗作用在每一帧上，用于防止分帧后产生的频谱泄露（分帧后每一帧的开始和结束都会出现间断，因此分割的帧越多，与原始信号的误差就越大，加窗就是为了解决这个问题，使得帧信号之间变得连续，并且让每一帧都表现出周期函数的特性）。后续的所有分析都是在语音信号短时平稳这个假设条件下进行的，即后续的分析都属于短时分析，均是在信号的每一帧上单独进行的。

   > 频谱泄露是指任何其他类型的操作产生了新的频率成分。正弦波在截断范围内具有整数个周期时不会发生频谱泄露，而当具有非整数个周期时会多出其他频率的分量，因此可以推断频谱泄露一般是由信号被非周期截断产生的。
   >
   > 加窗就是为了避免这种情况。不同的窗函数对频谱泄露的缓解程度不同，其总泄漏是通过等效噪声带宽（ENBW）来衡量的。好的窗函数应该满足频谱的能量主要集中在主瓣，尽量使旁瓣的能量低，使得窗口内的信号近似具有周期性。但加窗使得每一帧两端的信号变弱，为了缓解这个问题，帧与帧之间或有重叠部分，这就是帧移小于帧长的目的。

1. 后续处理：时域分析、频域分析等。

## 笔记摘要

### 什么是信号？

信号是信息的载体，通过信号可以传递信息：

1. 上课铃声——声信号，表示该上课了；
2. 十字路口的红绿灯——光信号，指挥交通；
3. 电视机天线接受的电视信息——电信号；
4. 广告牌上的文字、图象信号等等。

信号是携带信息的函数：

1. 声音：Represent air pressure as a function of time at a point in space；
2. 黑白照片：Represents light intensity as a function of two spatial coordinates；
3. 视频信号：Consists of a sequence of images called frames, and is a function of 3 variables: 2 spatial coordinates and time。

### 信号的分类

1. 根据幅度的统计特性，信号可分为确定性信号和随机信号（平稳/非平稳）：

​	![image-20211209001355024](../assets/image-20211209001355024.png)

2. 根据信号自变量和幅度的连续性，信号可分为模拟信号、时域离散信号、幅度离散信号和数字信号：

   模拟信号 =采样（均匀间隔挑点，时间离散化）=> 时域离散信号

   模拟信号 =量化（均匀范围拍扁，幅度离散化）=> 幅度离散信号

   模拟信号 =采样、量化=> 数字信号

### 语音特征

语音的特征提取：将输入的样点序列转换成特征向量序列，一个特征向量用于表示一个音频片段，称为一帧（Frame）。一帧包含若干样点，在语音识别中，常用25ms作为帧长（Frame length）。为了捕捉语音信号的连续变化，避免帧之间的特征突变，每隔10ms取一帧，即帧移（Frame shift）为10ms。

语音时域信号作为波形采样点，一般是不能直接用于识别的。时域信号的主要问题是难以找到发音规律，即使是很类似的发音，在时域上也可能看起来非常不同。事实上，我们人类的听觉器官是通过频域而不是波形来辨认声音的。把声音进行短时傅里叶变换（STFT），就得到了声音的频谱。因此，我们以帧为单位，依据听觉感知机理，按需调整声音片段频谱中各个成分的幅值，并将其参数化，得到适合表示语音信号特性的向量，这就是声学特征（Acoustic Feature）。声学特征把波形分成若干离散的帧，整个波形可以看作是一个矩阵，下图展示了波形和声学特征在时间上的对应关系。波形被分为了很多帧，每一帧都用一个12维的向量表示，色块的颜色深浅表示向量值的大小。

![epub_31391839_159](https://res.weread.qq.com/wrepub/epub_31391839_159)

其中，梅尔频率倒谱系数（MFCCs）是最常见的声学特征，其提取流程如下。

1. 对语音滑动加窗，从而实现分帧。通常帧长25ms，帧移10ms，这样可以保证帧内信号的平稳性，并使帧之间有交叠。
2. 对每一帧做快速傅里叶变换（Fast Fourier Transform，FFT），并计算功率谱。
3. 对功率谱应用梅尔滤波器组，获取每个滤波器内的对数能量作为系数。
4. 对得到的梅尔滤波器对数能量向量做离散余弦变换（Discrete CosineTransform，DCT）。

通过设定DCT的输出个数，可以得到不同维数的MFCCs特征，上图的例子中就使用了12维输出。除MFCCs特征外，FilterBank、PLP也是常用的特征。FilterBank有时也写作Fbank，是不做DCT的MFCCs，保留了特征维间的相关性，在用卷积神经网络作为声学模型时，通常选用Fbank作为特征。PLP特征提取自线性预测系数（Linear Prediction Coefficient，LPC）。几种特征的关系如下图所示。

<img src="../assets/image-20211209003046910.png" alt="image-20211209003046910" style="zoom:50%;" />

特征变换是指将一帧声学特征经过某种变换，转换为另外一帧特征，也就是说，特征变换的输入是一帧特征矢量，输出也是一帧特征矢量。

1. 无监督特征变换是指不依赖标注的特征变换，常用的无监督特征变换技术包括差分（在一定的窗长内，计算前后帧的差分特征，补充到当前特征上）、拼帧（在一定的窗长内，将前后若干帧拼接成一帧特征）和归一化（即倒谱均值方差归一化 (CMVN)，目的是将输入的声学特征进行规整，使其符合正态分布，即均值为零矢量，方差为单位矩阵）。

2. 有监督特征变换借助标注信息，估计一组变换系数，增强输入特征的表征能力。有监督特征变换最常用的表现形式是将输入乘以一个特征变换矩阵，而特征变换矩阵的估计方法主要分为线性判别分析（LDA）和最大似然线性变换（MLLT）。

   <img src="https://res.weread.qq.com/wrepub/epub_31391839_233" alt="img" style="zoom:50%;" />

### 各种图谱

时域谱、频域谱（幅度谱、相位谱）

1. 时域谱：x轴为时间、y轴为幅度
2. 频域谱：将时域谱分解为多种频率的正弦波后所得到的图谱（通过傅里叶变换可实现时频转换）
3. 幅度谱：x轴为频率、y轴为幅度
4. 相位谱：x轴为时间、y轴为相位

<img src="https://pic3.zhimg.com/4695ce06197677bab880cd55b6846f12_b.jpg" alt="img" style="zoom:67%;" />

语谱图：x轴为时间，y轴为频率，z轴为幅度（对应下图中的黑白条）。

<img src="https://img-blog.csdn.net/20130623210019187?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvem91eHkwOQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt="img" style="zoom: 67%;" />

> 语谱图的理解：将一帧语音的频谱通过坐标表示出来，如下图左所示。然后将左边的频谱旋转90度得到中间的图，接着把这些幅度映射到一个灰度级表示（也可以理解为将连续的幅度量化为256个量化值，0表示黑，255表示白色），幅度值越大，相应的区域越黑。这样就得到了最右边的图。那为什么要这样呢？为的是增加时间这个维度，这样就可以显示一段语音而不是一帧语音的频谱。
>
> <img src="https://img-blog.csdn.net/20130623205928484?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvem91eHkwOQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt="img" style="zoom:67%;" />

### MFCC

<img src="../assets/MFCC.jpeg" alt="MFCC" style="zoom:67%;" />

## 参考链接

[语音识别项目整理(一) 音频预处理 - 博客园 (cnblogs.com)](https://www.cnblogs.com/shiyublog/p/11245791.html#1.1-模拟音频信号)

[傅里叶分析之掐死教程（完整版）- 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/19763358)

[语音信号处理之（四）梅尔频率倒谱系数（MFCC）- CSDN博客](https://blog.csdn.net/zouxy09/article/details/9156785)

[语音信号处理基础（五）——语音分帧与加窗 - CSDN博客](https://blog.csdn.net/qq_40644291/article/details/103091188)

[分帧、加窗和DFT - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/397643730)

[如何用深度学习进行语音识别？ - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/24703268)
