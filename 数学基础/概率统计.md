# 朴素贝叶斯算法

> 参考文章：
>
> 1. [带你理解朴素贝叶斯分类算法 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/26262151)
> 2. [朴素贝叶斯分类器的应用 - 阮一峰的网络日志 (ruanyifeng.com)](https://www.ruanyifeng.com/blog/2013/12/naive_bayes_classifier.html)
> 3. [算法杂货铺——分类算法之朴素贝叶斯分类(Naive Bayesian classification) - T2噬菌体 - 博客园 (cnblogs.com)](https://www.cnblogs.com/leoo2sk/archive/2010/09/17/1829190.html)

朴素贝叶斯算法就是根据事物的特征来利用贝叶斯定理对事物进行分类的算法。该算法的流程如下：

1. 设 $x=\left\{a_{1}, a_{2}, \ldots, a_{m}\right\}$ 为待分类项，其中的每个 $a$ 为 $x$ 的一个特征。
2. 有类别集合 $C=\left\{y_{1}, y_{2}, \ldots, y_{n}\right\}$ 。
3. 计算 $x$ 属于每一类的概率，即 $P\left(y_{1} \mid x\right),P\left(y_{2} \mid x\right),\ldots,P\left(y_{n}\mid x\right)$  。
4. 如果  $P\left(y_{k} \mid x\right)=\max \left\{P\left(y_{1} \mid x\right), P\left(y_{2} \mid x\right), \ldots, P\left(y_{n} \mid x\right)\right\}$，则 $x \in y_{k}$。

其中在第三步时需要利用贝叶斯定理来计算概率：

1. 贝叶斯定理：$P(B \mid A)=\frac{P(A \mid B) P(B)}{P(A)}$，在朴素贝叶斯算法中等同于：

   $\mathrm{p}(类别|待分类项)=\mathrm{p}(类别|特征1,特征2,...,特征m)=\frac{p(特征1,特征2,...,特征m|类别)p(类别)}{\mathrm{p}(特征1,特征2,...,特征m)}$

2. 朴素贝叶斯算法假定待分类项中的每个特征都是相互独立，因此贝叶斯定理可以进一步变换为：

   $\mathrm{p}(类别|特征1,特征2,...,特征m)=\frac{p(特征1|类别)p(特征2|类别)...p(特征m|类别)p(类别)}{\mathrm{p}(特征1)\mathrm{p}(特征2)...\mathrm{p}(特征m)}$

3. $\mathrm{p}(类别c|待分类项d)$ 表示待分类项 d 属于类别 c 的概率。

4. $p(特征a|类别b)$ 表示属于类别 b 的项具有特征 a 的概率，可以通过统计来计算。

   - 当特征 a 是离散值时，这个概率等于属于类别 b 的所有样本中具有特征 a 的项占这些样本的比例；

   - 当特征 a 是连续值时，有两种计算方法：

     ① 转换为散值：为特征 a 划分区间，用区间代替特征 a 来计算概率，此时概率就等于属于类别 b 的所有样本中其特征 a 的值处于某个区间的项占这些样本的比例；

     ② 利用分布概率密度：找到属于类别 b 的所有样本中其特征 a 满足的分布，此时概率就等于该分布的概率密度函数值。

> 先验概率 P(x)：可以通过统计或已有经验得到的概率，比如从箱子中取出黑球的概率，我们可以通过计算黑球在箱子中的占比来得到，而掷硬币正面朝上的1/2概率，我们是根据已有经验来判断的。
>
> 条件概率 P(x|y)：假定在条件 y 下，出现 x 这种情况的概率。
>
> 后验概率 P(x|y)：已经发生了结果 y，我们推测由事件 x 造成这种结果的概率是多少。
